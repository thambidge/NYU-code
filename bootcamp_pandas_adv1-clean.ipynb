{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Advanced Pandas:  Cleaning data \n",
    "\n",
    "Probably the best thing about Pandas is its extensive toolset for managing data. Here we describe features of Pandas that allow us to clean data that, for reasons beyond our control, comes in a form that's not immediately amendable to analysis. This is the first of several such notebooks.  \n",
    "\n",
    "Outline:  \n",
    "\n",
    "* [Want operator](#want).  Start with what we want to end up, then figure out how to get there.  \n",
    "* [String methods](#strings).  Fixing string variables, especially strings that should really be numbers.  \n",
    "* [Missing values](#missing).  Marking, dropping, counting missing values.    \n",
    "* [Selecting variables and observations](#selection).  Choose the variables and observations we want by their labels.\n",
    "* [Boolean selection](#boolean).  This is mostly what we do:  choose observations from conditions.  We use comparisons to produce Boolean variables and then use the Boolean variables to select observations that are `True`.  The next two methods extend this capability.  \n",
    "* [The `isin` method](#isin).  Choose observations whose values are in lists you specify. \n",
    "* [The `contains` method](#contains).  Flag observations that contain a specific piece of text.  Another string method, operates through Booleans.  \n",
    "\n",
    "<!--\n",
    "* [The `query` method](#query).  Similar capability using database syntax.  This is one of many examples in which **SQL database** tools have been built into Pandas.  \n",
    "--> \n",
    "\n",
    "**Note: requires internet access to run.**  \n",
    "\n",
    "<!-- \n",
    "internal links http://sebastianraschka.com/Articles/2014_ipython_internal_links.html\n",
    "-->\n",
    "\n",
    "This Jupyter notebook was created by Dave Backus, Chase Coleman, Spencer Lyon and Balint Szoke for the NYU Stern course [Data Bootcamp](http://nyu.data-bootcamp.com/).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=prelims></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:  3.6.0 |Anaconda custom (x86_64)| (default, Dec 23 2016, 13:19:00) \n",
      "[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]\n",
      "Pandas version:  0.19.2\n",
      "Today:  2017-05-10\n"
     ]
    }
   ],
   "source": [
    "import sys                             # system module \n",
    "import pandas as pd                    # data package\n",
    "import matplotlib.pyplot as plt        # graphics module  \n",
    "import datetime as dt                  # date and time module\n",
    "import numpy as np                     # foundation for pandas \n",
    "\n",
    "%matplotlib inline                     \n",
    "\n",
    "# check versions (overkill, but why not?)\n",
    "print('Python version: ', sys.version)\n",
    "print('Pandas version: ', pd.__version__)\n",
    "print('Today: ', dt.date.today())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=want></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The want operator \n",
    "\n",
    "We need to know what we're trying to do -- what we **want** the data to look like. To borrow a phrase from our friend Tom Sargent, we say that we **apply the want operator**.  \n",
    "\n",
    "Some problems we've run across that ask to be solved:\n",
    "\n",
    "* Numerical data is contaminated by commas (marking thousands) or dollar signs.  \n",
    "* Row and column labels are contaminated.  \n",
    "* Missing values are marked erratically.  \n",
    "* We have too much data, would prefer to choose a subset.  \n",
    "* Variables run across rows rather than down columns.  \n",
    "\n",
    "What we want in each case is the opposite of what we have:  we want nicely formatted numbers, clean row and column labels, and so on.  \n",
    "\n",
    "We'll solve the first four problems here, the last one in the next notebook.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:  Chipotle data \n",
    "\n",
    "This data comes from a [New York Times story](http://www.nytimes.com/interactive/2015/02/17/upshot/what-do-people-actually-order-at-chipotle.html) about the number of calories in a typical order at Chipotle.  The topic doesn't particularly excite us, but the data raises a number of issues that come up repeatedly. We adapt some code written by [Daniel Forsyth](http://www.danielforsyth.me/pandas-burritos-analyzing-chipotle-order-data-2/). \n",
    "\n",
    "**Note:** The [file](https://raw.githubusercontent.com/TheUpshot/chipotle/master/orders.tsv) is a tsv (Tab Separated Values) file, so we need to set the separator accordingly when we call `pandas`' `read_csv` method. Remember that the default value of `sep` is `sep=','` (see the docstring). We can change it to tabular by wrinting `sep='\\t'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable dtypes:\n",
      "order_id               int64\n",
      "quantity               int64\n",
      "item_name             object\n",
      "choice_description    object\n",
      "item_price            object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>item_name</th>\n",
       "      <th>choice_description</th>\n",
       "      <th>item_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Chips and Fresh Tomato Salsa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$2.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Izze</td>\n",
       "      <td>[Clementine]</td>\n",
       "      <td>$3.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Nantucket Nectar</td>\n",
       "      <td>[Apple]</td>\n",
       "      <td>$3.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Chips and Tomatillo-Green Chili Salsa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$2.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Chicken Bowl</td>\n",
       "      <td>[Tomatillo-Red Chili Salsa (Hot), [Black Beans...</td>\n",
       "      <td>$16.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  quantity                              item_name  \\\n",
       "0         1         1           Chips and Fresh Tomato Salsa   \n",
       "1         1         1                                   Izze   \n",
       "2         1         1                       Nantucket Nectar   \n",
       "3         1         1  Chips and Tomatillo-Green Chili Salsa   \n",
       "4         2         2                           Chicken Bowl   \n",
       "\n",
       "                                  choice_description item_price  \n",
       "0                                                NaN     $2.39   \n",
       "1                                       [Clementine]     $3.39   \n",
       "2                                            [Apple]     $3.39   \n",
       "3                                                NaN     $2.39   \n",
       "4  [Tomatillo-Red Chili Salsa (Hot), [Black Beans...    $16.98   "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/TheUpshot/chipotle/master/orders.tsv'\n",
    "chipotle = pd.read_csv(url, sep='\\t')               # tab (\\t) separated values \n",
    "print('Variable dtypes:\\n', chipotle.dtypes, sep='')\n",
    "chipotle.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment.** Note that the variable `item_price` has dtype object. The reason is evidently the dollar sign.  We **want** to have it as a number, specifically a float.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:  Data Bootcamp entry poll\n",
    "\n",
    "This is the poll we did at the start of the course.  Responses were collected in a Google spreadsheet, which we converted to a csv and uploaded to our [website](https://raw.githubusercontent.com/NYUDataBootcamp/Materials/master/Data/entry_poll_spring17.csv).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url1 = \"https://raw.githubusercontent.com/NYUDataBootcamp/\"\n",
    "url2 = \"Materials/master/Data/entry_poll_spring17.csv\"\n",
    "url = url1 + url2 \n",
    "entry_poll = pd.read_csv(url) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entry_poll.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Dimensions:', entry_poll.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Data types:\\n\\n', entry_poll.dtypes, sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments.** This is mostly text data, which means it's assigned the dtype object. There are two things that would make the data easier to work with:\n",
    "\n",
    "> **First:** The column names are excessively verbose.  This one's easy:  We replace them with single words.  Which we do below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time',\n",
       " 'why',\n",
       " 'program',\n",
       " 'programming',\n",
       " 'prob_stats',\n",
       " 'major',\n",
       " 'career',\n",
       " 'data',\n",
       " 'topics']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (1) create list of strings with the new varnames\n",
    "newnames = ['time', 'why', 'program', 'programming', 'prob_stats', 'major', 'career', 'data', 'topics']\n",
    "newnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (2) Use the str.title() string method to make the varnames prettier\n",
    "newnames = [name.title() for name in newnames]             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`str.title()` returns a copy of the string in which first characters of all the words are capitalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Time',\n",
       " 'Why',\n",
       " 'Program',\n",
       " 'Programming',\n",
       " 'Prob_Stats',\n",
       " 'Major',\n",
       " 'Career',\n",
       " 'Data',\n",
       " 'Topics']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Why</th>\n",
       "      <th>Program</th>\n",
       "      <th>Programming</th>\n",
       "      <th>Prob_Stats</th>\n",
       "      <th>Major</th>\n",
       "      <th>Career</th>\n",
       "      <th>Data</th>\n",
       "      <th>Topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/26/2017 12:06:11</td>\n",
       "      <td>To help with my career</td>\n",
       "      <td>Undergraduate business</td>\n",
       "      <td>None</td>\n",
       "      <td>I have taken one probability or statistics course</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Consulting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Multivariate regression, Web scraping, Machine...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Time                     Why                 Program  \\\n",
       "0  1/26/2017 12:06:11  To help with my career  Undergraduate business   \n",
       "\n",
       "  Programming                                         Prob_Stats    Major  \\\n",
       "0        None  I have taken one probability or statistics course  Finance   \n",
       "\n",
       "       Career Data                                             Topics  \n",
       "0  Consulting  NaN  Multivariate regression, Web scraping, Machine...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (3) assign newnames to the variables\n",
    "entry_poll.columns = newnames  \n",
    "entry_poll.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Second:** The second one is harder.  The question about special topics of interest says \"mark all that apply.\"  In the spreadsheet, we have a list of every choice the person checked.  Our want is to count the number of each type of response.  For example, we might **want** a bar chart that gives us the number of each response. The question is how we get there.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check multi-response question to see what we're dealing with \n",
    "entry_poll['Topics'].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Comment.**  Note the commas separating answers with more than one choice.  We **want** to unpack them somehow.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:  OECD healthcare statistics \n",
    "\n",
    "The OECD collects [healthcare data](http://www.oecd.org/els/health-systems/health-data.htm) on lots of (mostly rich) countries, which is helpful in producing comparisons.  Here we use a [spreadsheet](http://www.oecd.org/health/health-systems/OECD-Health-Statistics-2016-Frequently-Requested-Data.xls) that can be found under Frequently Requested Data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OECD Health Statistics 2016 - Frequently Requested Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>OCTOBER 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>Note: Latvia has joined the OECD in July 2016,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>OECD Health Statistics 2016: website</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    OECD Health Statistics 2016 - Frequently Requested Data\n",
       "NaN                                       OCTOBER 2016     \n",
       "NaN                                                NaN     \n",
       "NaN  Note: Latvia has joined the OECD in July 2016,...     \n",
       "NaN                                                NaN     \n",
       "NaN               OECD Health Statistics 2016: website     "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url1 = 'http://www.oecd.org/health/health-systems/'\n",
    "url2 = 'OECD-Health-Statistics-2016-Frequently-Requested-Data.xls'\n",
    "oecd = pd.read_excel(url1 + url2)\n",
    "oecd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks bad. But we can always use `pd.read_excel?`. Let's look into the excel file. \n",
    "* multiple sheets (want: `Physicians`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HEALTH CARE RESOURCES</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 49</th>\n",
       "      <th>Unnamed: 50</th>\n",
       "      <th>Unnamed: 51</th>\n",
       "      <th>Unnamed: 52</th>\n",
       "      <th>Unnamed: 53</th>\n",
       "      <th>Unnamed: 54</th>\n",
       "      <th>Unnamed: 55</th>\n",
       "      <th>Unnamed: 56</th>\n",
       "      <th>Unnamed: 57</th>\n",
       "      <th>Unnamed: 58</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Physicians, Density per 1 000 population (head...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1960</td>\n",
       "      <td>1961</td>\n",
       "      <td>1962</td>\n",
       "      <td>1963</td>\n",
       "      <td>1964</td>\n",
       "      <td>1965</td>\n",
       "      <td>1966</td>\n",
       "      <td>1967</td>\n",
       "      <td>1968</td>\n",
       "      <td>...</td>\n",
       "      <td>2008</td>\n",
       "      <td>2009</td>\n",
       "      <td>2010</td>\n",
       "      <td>2011</td>\n",
       "      <td>2012</td>\n",
       "      <td>2013</td>\n",
       "      <td>2014</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014 (or nearest year)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Australia 1</td>\n",
       "      <td>..</td>\n",
       "      <td>1.13</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.24</td>\n",
       "      <td>...</td>\n",
       "      <td>3.02</td>\n",
       "      <td>3.12</td>\n",
       "      <td>..</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.47</td>\n",
       "      <td>..</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Austria 1</td>\n",
       "      <td>1.59</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.69</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.99</td>\n",
       "      <td>5.05</td>\n",
       "      <td>5.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               HEALTH CARE RESOURCES Unnamed: 1 Unnamed: 2  \\\n",
       "0  Physicians, Density per 1 000 population (head...        NaN        NaN   \n",
       "1                                                NaN        NaN        NaN   \n",
       "2                                                NaN       1960       1961   \n",
       "3                                        Australia 1         ..       1.13   \n",
       "4                                          Austria 1       1.59       1.58   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6 Unnamed: 7 Unnamed: 8  \\\n",
       "0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "2       1962       1963       1964       1965       1966       1967   \n",
       "3         ..         ..       1.23       1.22       1.23       1.26   \n",
       "4       1.57       1.56       1.56       1.56       1.57       1.58   \n",
       "\n",
       "  Unnamed: 9           ...           Unnamed: 49 Unnamed: 50 Unnamed: 51  \\\n",
       "0        NaN           ...                   NaN         NaN         NaN   \n",
       "1        NaN           ...                   NaN         NaN         NaN   \n",
       "2       1968           ...                  2008        2009        2010   \n",
       "3       1.24           ...                  3.02        3.12          ..   \n",
       "4        1.6           ...                   4.6        4.69         4.8   \n",
       "\n",
       "  Unnamed: 52 Unnamed: 53 Unnamed: 54 Unnamed: 55 Unnamed: 56 Unnamed: 57  \\\n",
       "0         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2        2011        2012        2013        2014        2015         NaN   \n",
       "3        3.32        3.31         3.4        3.47          ..         NaN   \n",
       "4        4.84         4.9        4.99        5.05        5.13         NaN   \n",
       "\n",
       "              Unnamed: 58  \n",
       "0                     NaN  \n",
       "1                     NaN  \n",
       "2  2014 (or nearest year)  \n",
       "3                    3.47  \n",
       "4                    5.05  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oecd = pd.read_excel(url1 + url2, sheetname='Physicians')\n",
    "oecd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The first three lines are empty. Skip those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>1966</th>\n",
       "      <th>1967</th>\n",
       "      <th>1968</th>\n",
       "      <th>...</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>Unnamed: 57</th>\n",
       "      <th>2014 (or nearest year)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia 1</td>\n",
       "      <td>..</td>\n",
       "      <td>1.13</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.24</td>\n",
       "      <td>...</td>\n",
       "      <td>3.02</td>\n",
       "      <td>3.12</td>\n",
       "      <td>..</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.47</td>\n",
       "      <td>..</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Austria 1</td>\n",
       "      <td>1.59</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.69</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.99</td>\n",
       "      <td>5.05</td>\n",
       "      <td>5.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Belgium 1</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.46</td>\n",
       "      <td>1.49</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.55</td>\n",
       "      <td>...</td>\n",
       "      <td>2.92</td>\n",
       "      <td>2.92</td>\n",
       "      <td>2.92</td>\n",
       "      <td>2.91</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.97</td>\n",
       "      <td>..</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Canada 2</td>\n",
       "      <td>..</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.33</td>\n",
       "      <td>...</td>\n",
       "      <td>2.26</td>\n",
       "      <td>2.34</td>\n",
       "      <td>2.38</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.57</td>\n",
       "      <td>2.61</td>\n",
       "      <td>..</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chile 3</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>...</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  1960  1961  1962  1963  1964  1965  1966  1967  1968  \\\n",
       "0  Australia 1    ..  1.13    ..    ..  1.23  1.22  1.23  1.26  1.24   \n",
       "1    Austria 1  1.59  1.58  1.57  1.56  1.56  1.56  1.57  1.58   1.6   \n",
       "2    Belgium 1  1.28  1.35   1.4  1.42  1.44  1.46  1.49  1.52  1.55   \n",
       "3     Canada 2    ..  1.14  1.22  1.24  1.26  1.27   1.3  1.32  1.33   \n",
       "4      Chile 3    ..    ..    ..    ..    ..    ..    ..    ..    ..   \n",
       "\n",
       "           ...            2008  2009  2010  2011  2012  2013  2014  2015  \\\n",
       "0          ...            3.02  3.12    ..  3.32  3.31   3.4  3.47    ..   \n",
       "1          ...             4.6  4.69   4.8  4.84   4.9  4.99  5.05  5.13   \n",
       "2          ...            2.92  2.92  2.92  2.91  2.93  2.95  2.97    ..   \n",
       "3          ...            2.26  2.34  2.38  2.46  2.51  2.57  2.61    ..   \n",
       "4          ...              ..    ..  1.43  1.58  1.74  1.88  2.02   NaN   \n",
       "\n",
       "  Unnamed: 57 2014 (or nearest year)  \n",
       "0         NaN                   3.47  \n",
       "1         NaN                   5.05  \n",
       "2         NaN                   2.97  \n",
       "3         NaN                   2.61  \n",
       "4         NaN                   2.02  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oecd = pd.read_excel(url1 + url2, sheetname='Physicians', skiprows=3)\n",
    "oecd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Would be nice to have the countries as indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>1966</th>\n",
       "      <th>1967</th>\n",
       "      <th>1968</th>\n",
       "      <th>1969</th>\n",
       "      <th>...</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>Unnamed: 57</th>\n",
       "      <th>2014 (or nearest year)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Australia 1</th>\n",
       "      <td>..</td>\n",
       "      <td>1.13</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.26</td>\n",
       "      <td>...</td>\n",
       "      <td>3.02</td>\n",
       "      <td>3.12</td>\n",
       "      <td>..</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.47</td>\n",
       "      <td>..</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austria 1</th>\n",
       "      <td>1.59</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.63</td>\n",
       "      <td>...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.69</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.99</td>\n",
       "      <td>5.05</td>\n",
       "      <td>5.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Belgium 1</th>\n",
       "      <td>1.28</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.46</td>\n",
       "      <td>1.49</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.55</td>\n",
       "      <td>...</td>\n",
       "      <td>2.92</td>\n",
       "      <td>2.92</td>\n",
       "      <td>2.92</td>\n",
       "      <td>2.91</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.97</td>\n",
       "      <td>..</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Canada 2</th>\n",
       "      <td>..</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.38</td>\n",
       "      <td>...</td>\n",
       "      <td>2.26</td>\n",
       "      <td>2.34</td>\n",
       "      <td>2.38</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.57</td>\n",
       "      <td>2.61</td>\n",
       "      <td>..</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chile 3</th>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>...</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             1960  1961  1962  1963  1964  1965  1966  1967  1968  1969  \\\n",
       "Australia 1    ..  1.13    ..    ..  1.23  1.22  1.23  1.26  1.24  1.26   \n",
       "Austria 1    1.59  1.58  1.57  1.56  1.56  1.56  1.57  1.58   1.6  1.63   \n",
       "Belgium 1    1.28  1.35   1.4  1.42  1.44  1.46  1.49  1.52  1.55  1.55   \n",
       "Canada 2       ..  1.14  1.22  1.24  1.26  1.27   1.3  1.32  1.33  1.38   \n",
       "Chile 3        ..    ..    ..    ..    ..    ..    ..    ..    ..    ..   \n",
       "\n",
       "                     ...            2008  2009  2010  2011  2012  2013  2014  \\\n",
       "Australia 1          ...            3.02  3.12    ..  3.32  3.31   3.4  3.47   \n",
       "Austria 1            ...             4.6  4.69   4.8  4.84   4.9  4.99  5.05   \n",
       "Belgium 1            ...            2.92  2.92  2.92  2.91  2.93  2.95  2.97   \n",
       "Canada 2             ...            2.26  2.34  2.38  2.46  2.51  2.57  2.61   \n",
       "Chile 3              ...              ..    ..  1.43  1.58  1.74  1.88  2.02   \n",
       "\n",
       "             2015 Unnamed: 57 2014 (or nearest year)  \n",
       "Australia 1    ..         NaN                   3.47  \n",
       "Austria 1    5.13         NaN                   5.05  \n",
       "Belgium 1      ..         NaN                   2.97  \n",
       "Canada 2       ..         NaN                   2.61  \n",
       "Chile 3       NaN         NaN                   2.02  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oecd = pd.read_excel(url1 + url2, \n",
    "                     sheetname='Physicians', \n",
    "                     skiprows=3, \n",
    "                     index_col=0)\n",
    "oecd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The last two columns contain junk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 58)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oecd.shape   # drop 57th and 58th columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>1966</th>\n",
       "      <th>1967</th>\n",
       "      <th>1968</th>\n",
       "      <th>1969</th>\n",
       "      <th>...</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Australia 1</th>\n",
       "      <td>..</td>\n",
       "      <td>1.13</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.26</td>\n",
       "      <td>...</td>\n",
       "      <td>2.84</td>\n",
       "      <td>3.01</td>\n",
       "      <td>3.02</td>\n",
       "      <td>3.12</td>\n",
       "      <td>..</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.47</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austria 1</th>\n",
       "      <td>1.59</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.63</td>\n",
       "      <td>...</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.54</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.69</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.99</td>\n",
       "      <td>5.05</td>\n",
       "      <td>5.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Belgium 1</th>\n",
       "      <td>1.28</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.46</td>\n",
       "      <td>1.49</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.55</td>\n",
       "      <td>...</td>\n",
       "      <td>2.89</td>\n",
       "      <td>2.91</td>\n",
       "      <td>2.92</td>\n",
       "      <td>2.92</td>\n",
       "      <td>2.92</td>\n",
       "      <td>2.91</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.97</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Canada 2</th>\n",
       "      <td>..</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.38</td>\n",
       "      <td>...</td>\n",
       "      <td>2.18</td>\n",
       "      <td>2.22</td>\n",
       "      <td>2.26</td>\n",
       "      <td>2.34</td>\n",
       "      <td>2.38</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.57</td>\n",
       "      <td>2.61</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chile 3</th>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>...</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             1960  1961  1962  1963  1964  1965  1966  1967  1968  1969  ...   \\\n",
       "Australia 1    ..  1.13    ..    ..  1.23  1.22  1.23  1.26  1.24  1.26  ...    \n",
       "Austria 1    1.59  1.58  1.57  1.56  1.56  1.56  1.57  1.58   1.6  1.63  ...    \n",
       "Belgium 1    1.28  1.35   1.4  1.42  1.44  1.46  1.49  1.52  1.55  1.55  ...    \n",
       "Canada 2       ..  1.14  1.22  1.24  1.26  1.27   1.3  1.32  1.33  1.38  ...    \n",
       "Chile 3        ..    ..    ..    ..    ..    ..    ..    ..    ..    ..  ...    \n",
       "\n",
       "             2006  2007  2008  2009  2010  2011  2012  2013  2014  2015  \n",
       "Australia 1  2.84  3.01  3.02  3.12    ..  3.32  3.31   3.4  3.47    ..  \n",
       "Austria 1    4.45  4.54   4.6  4.69   4.8  4.84   4.9  4.99  5.05  5.13  \n",
       "Belgium 1    2.89  2.91  2.92  2.92  2.92  2.91  2.93  2.95  2.97    ..  \n",
       "Canada 2     2.18  2.22  2.26  2.34  2.38  2.46  2.51  2.57  2.61    ..  \n",
       "Chile 3        ..    ..    ..    ..  1.43  1.58  1.74  1.88  2.02   NaN  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is no skipcols argument, so let's google \"read_excel skip columns\" -> usecols\n",
    "oecd = pd.read_excel(url1 + url2, \n",
    "                     sheetname='Physicians', \n",
    "                     skiprows=3, \n",
    "                     index_col=0, \n",
    "                     usecols=range(57))\n",
    "oecd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What about the bottom of the table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oecd.tail()    # we are downloading the footnotes too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?pd.read_excel  # -> skip_footer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How many rows to skip??\n",
    "oecd.tail(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>1966</th>\n",
       "      <th>1967</th>\n",
       "      <th>1968</th>\n",
       "      <th>1969</th>\n",
       "      <th>...</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sweden 1</th>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>...</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3.69</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.82</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.97</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.12</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Switzerland 1</th>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>...</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>3.82</td>\n",
       "      <td>3.83</td>\n",
       "      <td>3.81</td>\n",
       "      <td>3.83</td>\n",
       "      <td>3.92</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.13</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turkey 2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.59</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.73</td>\n",
       "      <td>1.76</td>\n",
       "      <td>1.76</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United Kingdom 1</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.93</td>\n",
       "      <td>...</td>\n",
       "      <td>2.44</td>\n",
       "      <td>2.47</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.74</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.77</td>\n",
       "      <td>2.79</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United States 1</th>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>...</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.43</td>\n",
       "      <td>2.44</td>\n",
       "      <td>2.44</td>\n",
       "      <td>2.43</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.56</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  1960  1961  1962  1963  1964  1965  1966  1967  1968  1969  \\\n",
       "Sweden 1            ..    ..    ..    ..    ..    ..    ..    ..    ..    ..   \n",
       "Switzerland 1       ..    ..    ..    ..    ..    ..    ..    ..    ..    ..   \n",
       "Turkey 2           0.3  0.32  0.38  0.38  0.33  0.35  0.36  0.36  0.38  0.39   \n",
       "United Kingdom 1  0.85  0.86  0.87  0.87  0.87  0.87  0.88  0.89  0.91  0.93   \n",
       "United States 1     ..    ..    ..    ..    ..    ..    ..    ..    ..    ..   \n",
       "\n",
       "                 ...   2006  2007  2008  2009  2010  2011  2012  2013  2014  \\\n",
       "Sweden 1         ...   3.61  3.69  3.75  3.82  3.89  3.97  4.04  4.12    ..   \n",
       "Switzerland 1    ...     ..    ..  3.82  3.83  3.81  3.83  3.92  4.04  4.13   \n",
       "Turkey 2         ...   1.51  1.55  1.59  1.65  1.69   1.7  1.73  1.76  1.76   \n",
       "United Kingdom 1 ...   2.44  2.47  2.56  2.65   2.7  2.74  2.75  2.77  2.79   \n",
       "United States 1  ...   2.42  2.43  2.44  2.44  2.43  2.46  2.50  2.56    ..   \n",
       "\n",
       "                 2015  \n",
       "Sweden 1           ..  \n",
       "Switzerland 1      ..  \n",
       "Turkey 2           ..  \n",
       "United Kingdom 1  2.8  \n",
       "United States 1    ..  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oecd = pd.read_excel(url1 + url2, \n",
    "                     sheetname='Physicians', \n",
    "                     skiprows=3, \n",
    "                     index_col=0, \n",
    "                     usecols=range(57), \n",
    "                     skip_footer=20)\n",
    "oecd.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oecd.dtypes[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have a couple issues.  \n",
    "\n",
    "* The index includes a space and a number:  `Australia 1`, `Chile 3`, etc.  We care about this because when we plot the data across countries, the country labels are going to be country names, so we **want** them in a better form than this.  \n",
    "* The `..`'s in the sheet lead us to label any column that includes them as dtype object.  Here we **want** to label them as missing values.  \n",
    "* If we **want** to plot each country against time, then we'll need to switch the rows and columns somehow, so that the x axis in the plot (the year) is the index and not the column label.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:  World Economic Outlook \n",
    "\n",
    "The IMF's [World Economic Outlook database](http://www.imf.org/external/pubs/ft/weo/2016/02/weodata/download.aspx) contains a broad range of macroeconomic data for a large number of countries.  It's updated twice a year and is a go-to source for things like current account balances (roughly, the trade balance) and government debt and deficits.  It also has a few quirks, as we'll see.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example.** Run the following code as is, and with the `thousands` and `na_values` parameters commented out.  How do the dtypes differ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "XLRDError",
     "evalue": "Unsupported format, or corrupt file: Expected BOF record; found b'<html><h'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXLRDError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-00e763507315>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Try\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mweo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# NOT an excel file!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Tim/anaconda/lib/python3.6/site-packages/pandas/io/excel.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheetname, header, skiprows, skip_footer, index_col, names, parse_cols, parse_dates, date_parser, na_values, thousands, convert_float, has_index_names, converters, true_values, false_values, engine, squeeze, **kwds)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     return io._parse_excel(\n",
      "\u001b[0;32m/Users/Tim/anaconda/lib/python3.6/site-packages/pandas/io/excel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, io, **kwds)\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;31m# N.B. xlrd.Book has a read attribute too\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Tim/anaconda/lib/python3.6/site-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0mformatting_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatting_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0mon_demand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_demand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mragged_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mragged_rows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m         )\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Tim/anaconda/lib/python3.6/site-packages/xlrd/book.py\u001b[0m in \u001b[0;36mopen_workbook_xls\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mbk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_time_stage_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mbiff_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXL_WORKBOOK_GLOBALS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbiff_version\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mXLRDError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can't determine file's BIFF version\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Tim/anaconda/lib/python3.6/site-packages/xlrd/book.py\u001b[0m in \u001b[0;36mgetbof\u001b[0;34m(self, rqd_stream)\u001b[0m\n\u001b[1;32m   1228\u001b[0m             \u001b[0mbof_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected BOF record; met end of file'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopcode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbofcodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1230\u001b[0;31m             \u001b[0mbof_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected BOF record; found %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msavpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msavpos\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1231\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget2bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mMY_EOF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Tim/anaconda/lib/python3.6/site-packages/xlrd/book.py\u001b[0m in \u001b[0;36mbof_error\u001b[0;34m(msg)\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"reqd: 0x%04x\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrqd_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mbof_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mXLRDError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unsupported format, or corrupt file: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m         \u001b[0msavpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_position\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m         \u001b[0mopcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget2bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXLRDError\u001b[0m: Unsupported format, or corrupt file: Expected BOF record; found b'<html><h'"
     ]
    }
   ],
   "source": [
    "url = 'http://www.imf.org/external/pubs/ft/weo/2016/02/weodata/WEOOct2016all.xls'\n",
    "\n",
    "# Try\n",
    "weo = pd.read_excel(url)         # NOT an excel file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp,Why have you enrolled in this course?,What program are you enrolled in?,How much programming experience have you had?,How much experience with probability and statistics have you had?,What is your expected major or concentration?,What career path most interests you?,What kinds of data most interest you? List any that cross your mind.,If we have time -- and we may not -- what special topics would interest you? Check all that apply.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/26/2017 12:06:11,To help with my career,Unde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/27/2017 19:53:47,To help with my career,MS I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/27/2017 20:06:13,To help with my career,Grad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/27/2017 20:10:40,To help with my career,MBA,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/27/2017 21:10:36,To help with my career,EMBA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Timestamp,Why have you enrolled in this course?,What program are you enrolled in?,How much programming experience have you had?,How much experience with probability and statistics have you had?,What is your expected major or concentration?,What career path most interests you?,What kinds of data most interest you? List any that cross your mind.,If we have time -- and we may not -- what special topics would interest you? Check all that apply.\n",
       "0  1/26/2017 12:06:11,To help with my career,Unde...                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "1  1/27/2017 19:53:47,To help with my career,MS I...                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "2  1/27/2017 20:06:13,To help with my career,Grad...                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "3  1/27/2017 20:10:40,To help with my career,MBA,...                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "4  1/27/2017 21:10:36,To help with my career,EMBA...                                                                                                                                                                                                                                                                                                                                                                                                          "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try to open the file with a plain text editor (it is a TSV)\n",
    "weo = pd.read_csv(url, sep = '\\t')\n",
    "weo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful columns:\n",
    "   - 1, 2, 3, 4, 6 (indices)\n",
    "   - years, say from 1980 to 2016\n",
    "\n",
    "Need a list that specifies these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Timestamp,Why have you enrolled in this course?,What program are you enrolled in?,How much programming experience have you had?,How much experience with probability and statistics have you had?,What is your expected major or concentration?,What career path most interests you?,What kinds of data most interest you? List any that cross your mind.,If we have time -- and we may not -- what special topics would interest you? Check all that apply.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = list(weo.columns)\n",
    "names[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-18fc964e920b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# for var details\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdetails_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# for years\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0myears_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# for var details \n",
    "details_list = names[1:5] + [names[6]]\n",
    "# for years\n",
    "years_list = names[9:-6]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'details_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-55e0a8b7540d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdetails_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'details_list' is not defined"
     ]
    }
   ],
   "source": [
    "details_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'details_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-8aedb604ac97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                   \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ISO'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                   usecols=details_list + years_list)\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mweo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'details_list' is not defined"
     ]
    }
   ],
   "source": [
    "weo = pd.read_csv(url, \n",
    "                  sep = '\\t',\n",
    "                  index_col='ISO',\n",
    "                  usecols=details_list + years_list)\n",
    "weo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Look at the bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weo.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weo = pd.read_csv(url, \n",
    "                  sep = '\\t',\n",
    "                  index_col='ISO',\n",
    "                  usecols=details_list + years_list,\n",
    "                  skipfooter=1, engine='python')    # read_csv requires 'python' engine (otherwise warning)\n",
    "weo.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weo = pd.read_csv(url, \n",
    "                  sep = '\\t',\n",
    "                  index_col='ISO',\n",
    "                  usecols=details_list + years_list,\n",
    "                  skipfooter=1, engine='python',\n",
    "                  na_values='n/a')\n",
    "weo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weo.dtypes[:10]     # still not ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Notice the `,` for thousands. As we saw before, there is an easy fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weo = pd.read_csv(url, \n",
    "                  sep = '\\t',\n",
    "                  index_col='ISO',\n",
    "                  usecols=details_list + years_list,\n",
    "                  skipfooter=1, engine='python',\n",
    "                  na_values='n/a',\n",
    "                  thousands =',')\n",
    "weo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment.** This has several issues. Here's what we **want**:\n",
    "\n",
    "- We would like the variables to be in columns and have observations labeled 1980, 1981, etc. In other words, we want the years in the index.\n",
    "- We would like to make sure the data columns (1980, 1981, etc.) have dtype `float64`\n",
    "\n",
    "Here's what we might to do achieve what we want:\n",
    "\n",
    "- We could try to transpose the dataframe to get the years in the index. This is close, but not quite what we want (see below). We'll come back to this in the next notebook.\n",
    "- To make the data columns have dtype `float64` we need to warn pandas about the `,` thousand separators and `n/a` for missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question.**  Can we transpose the whole thing to get the data running down columns?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weo.T.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='strings'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------\n",
    "## String methods \n",
    "\n",
    "We can treat variables as strings in Pandas in much the same way we dealt with strings in core Python.  Run the code below to remind yourself how this works.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dollars = '$123.45'\n",
    "print('Type of variable dollars:', type(dollars))\n",
    "num = dollars.replace('$', '')\n",
    "num = float(num)\n",
    "print('Type of variable num:', type(num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pandas string methods.** We can do the same thing to all the observations of a variable with so-called **string methods**.  We append `.str` to a variable in a dataframe and then apply the string method of our choice.  If this is part of converting a number-like entry that has mistakenly been given dtype object, we then convert its dtype with the `astype` method.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example.**  Let's use a string method to fix the `item_price` variable in the Chipotle dataframe.  This has three parts: \n",
    "\n",
    "* Use the method `str` to identify this as a string method.\n",
    "* Apply the string method of our choice (here `replace`) to fix the string.\n",
    "* Use the `astype` method to convert the fixed-up string to a float. \n",
    "\n",
    "We start by making a copy of the `chp` dataframe that we can experiment with.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chipotle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a copy of the df to play with \n",
    "\n",
    "chipotle_num = chipotle.copy()\n",
    "print('Original dtype:', chipotle_num['item_price'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# delete dollar signs (dtype does not change!)\n",
    "\n",
    "chipotle_num['item_price'].str.replace('$', '').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# delete dollar signs, convert to float, AND assign back to chipotle_num in one line\n",
    "\n",
    "chipotle_num['item_price'] = chipotle_num['item_price'].str.replace('$', '').astype(float)\n",
    "print('New dtype:', chipotle_num['item_price'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assign back to chp for future use \n",
    "chipotle = chipotle_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Variable dtypes:\\n', chipotle.dtypes, sep='')\n",
    "chipotle.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Comment.** We did everything here in one line:  replace the dollar sign with a string method, then converted to float using `astype`.  If you think this is too dense, you might break it into two steps.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example.** Here we use the astype method again to convert the dtypes of weo into float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weo.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weo.head(1).dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to convert the year variables into float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weo['1980'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This error indicates that somewhere in `weo['1980']` there is a string value `--`. We want to convert that into `NaN`. Later we will see how we can do that directly. For now use `read_csv()` again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weo = pd.read_csv(url, \n",
    "                  sep = '\\t',\n",
    "                  index_col='ISO',\n",
    "                  usecols=details_list + years_list,\n",
    "                  skipfooter=1, engine='python',\n",
    "                  na_values=['n/a', '--'],\n",
    "                  thousands =',')\n",
    "weo.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# With that out of our way, we can do the conversion for one variable \n",
    "weo['1980'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# or for all numeric variables\n",
    "years = [str(year) for year in range(1980, 2017)]\n",
    "weo[years] = weo[years].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weo.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example.** Here we strip off the numbers at the end of the indexes in the OECD `docs` dataframe.  This involves some experimentation:  \n",
    "\n",
    "* Play with the `rsplit` method to see how it works.  \n",
    "* Apply `rsplit` to the example `country = 'United States 1'`.  \n",
    "* Use a string method to do this to all the entries of the variable `Country`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try this with an example first \n",
    "country = 'United States 1'\n",
    "\n",
    "# get documentation for the rsplit method\n",
    "country.rsplit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# an example \n",
    "country.rsplit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment.** Not quite, we only want to split once.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what about this?\n",
    "country.rsplit(maxsplit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# one more step, we want the first component of the list\n",
    "country.rsplit(maxsplit=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oecd.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oecd.index.str.rsplit(maxsplit=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#try\n",
    "oecd.index.str.rsplit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Note the TWO str's\n",
    "oecd.index.str.rsplit(n=1).str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#or use the str.get() method\n",
    "oecd.index.str.rsplit(n=1).str.get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oecd.index = oecd.index.str.rsplit(n=1).str.get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oecd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments.** \n",
    "\n",
    "* Note that we need two `str`'s here:  one to do the split, the other to extract the first element.  \n",
    "* For reasons that mystify us, we ran into problems when we used `maxsplit=1`, but it works with `n=1`. \n",
    "* This is probably more than you want to know, but file away the possibilities in case you need them.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='missing'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values \n",
    "\n",
    "It's important to label missing values, so that Pandas doesn't interpret entries as strings.  Pandas is also smart enough to ignore things labeled missing when it does calculations or graphs.  If we compute, for example, the mean of a variable, the default is to ignore missing values.  \n",
    "\n",
    "We've seen that we can label certain entries as missing values in read statements:  `read_csv`, `read_excel`, and so on.  Here we do it directly, mostly to remind ourselves what's involved.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marking missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example.** The `oecd` dataframe contains a number of instances of `..` (double period).  How can we mark them as missing values?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs = oecd\n",
    "docs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What to do.**  We use the replace method on the whole dataframe.  To mark something as missing, we replace it as `None`, which Pandas interprets as missing and labels `NaN`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs.replace(to_replace=['..'], value=[None]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment.**  Replace automatically updates the dtypes.  Here the double dots led us to label the variables as objects.  After the replace, they're now floats, as they should be.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docsna = docs.replace(to_replace=['..'], value=[None])\n",
    "docsna.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment.** Unlike the string methods we described earlier, this use of replace affects complete entries, not elements of string entries.  For example, suppose we tried to replace the periods in decimal numbers with an asterisk.  We could try the following, but it doesn't work:  the decimal numbers  don't change.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs.replace(to_replace=['.'], value=['*']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grab a variable to play with\n",
    "var = docsna[2013].head(10)\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# why not '2013'? check the type\n",
    "docsna.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# which ones are missing (\"null\")?\n",
    "var.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# which ones are not missing (\"not null\")?\n",
    "var.notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop the missing \n",
    "var.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Comment.** We usually don't have to worry about this, Pandas takes care of missing values automatically.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Comment.** Let's try a picture to give us a feeling of accomplishment. What else would you say we need?  How would we get it?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docsna[2013].plot.barh(figsize=(4, 12)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='selection'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting variables and observations \n",
    "\n",
    "The word **selection** refers to choosing a subset of variables or observations using their labels or index.  Similar methods are sometimes referred to as **slicing**, **subsetting**, **indexing**, **querying**, or **filtering**.  We'll treat the terms as synonymous.  \n",
    "\n",
    "There are lots of ways to do this.  Mostly we do \"Boolean\" selection, which we address in the next section.  We review more direct options here, mostly at high speed because they're not things we use much.  \n",
    "\n",
    "In the outline below, `df` is a dataframe, `var` and `varn` are variable names, `n1` and `n2` are integers,\n",
    "- `vlist = ['var1', 'var2']` is a list of variable names, and \n",
    "- `nlist = [0, 3, 4]` is a list of numerical variable or observation indexes and \n",
    "- `bools` is a list or pandas `Series` of booleans (`True` and `False`).  \n",
    "\n",
    "Some of the basic selection/indexing/slicing methods have the form:  \n",
    "\n",
    ">* `df[var]` extracts a variable -- a series, in other words.\n",
    ">* `df[vlist]` extracts a new dataframe consisting of the variables in `vlist`.  \n",
    ">* `df[nlist]` does the same thing.  \n",
    ">* `df[bools]`: extracts each _row_ where the corresponding element in `bools` is true. `len(bools)` must be equal to `df.size[0]`\n",
    ">* `df[n1:n2]` extracts observations `n1` to `n2-1`, the traditional slicing syntax.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we create a small dataframe to experiment with \n",
    "small = weo.head()\n",
    "small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example.** Let's try each of these in a different cell and see what they do:  \n",
    "    \n",
    "* `small[['Country', 'Units']]`\n",
    "* `small[[0, 4]]`\n",
    "* `small['2011']`\n",
    "* `small[1:3]`\n",
    "\n",
    "Can you explain the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small[['Country', 'Units']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small[[0, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small['2011']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small[[False, True, True, False, False]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series indexing\n",
    "\n",
    "Indexing a `Series` is a little different because we only have one column, so all indexing operations interact with rows.\n",
    "\n",
    "The rules here are a little subtle, so we'll show examples and add comments that explain what each example does\n",
    "\n",
    "In the list below `s` is a `Series`, `n` is an integer, `nlist = [0, 3]` is a list of integers, and `i` is a string, and `is` is a list of strings\n",
    "\n",
    "- `s[n]`: if the index has `dtype` int, this extracts the row with index `n`. Otherwise extracts the `n`th row (starting at zero)\n",
    "- `s[nlist]`: if the index has `dtype` int, this extracts rows with indices in `nlist` returning `NaN` if they don't appear. Otherwise extracts the rows at positions in `nlist`, filling with `NaN` for invalid positions\n",
    "- `s[i]`: if the index has `dtype` `object`, this extracts the row with index `i`, otherwise it is an error\n",
    "- `s[is]`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    5\n",
       "b    6\n",
       "c    7\n",
       "d    8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = pd.Series([5, 6, 7, 8], index=[\"a\", \"b\", \"c\", \"d\"])\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      50\n",
       "4      60\n",
       "2      70\n",
       "999    80\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2 = pd.Series([50, 60, 70, 80], index=[0, 4, 2, 999])\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index has dtype object, so using an int returns the value in that row (starting at 0)\n",
    "s1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# index has dtype int, so using an integer tries to find the that int in the \n",
    "# index and return the corresponding value and throws an error if it can't find it\n",
    "s2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s2[0]  # no error, 0 is in the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# index has dtype object, so a list of ints extracts those rows\n",
    "s1[[0, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# index has dtype int, so a list of ints tries to match each int to the index\n",
    "# it returns NaN where it can't find the index. Notice it **did not** return \n",
    "# `80` for 3\n",
    "s2[[0, 3, 999]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# index has type object, so a string finds row with matching index\n",
    "s1[\"c\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# index has dtype int, so using a string causes an error\n",
    "s2[\"c\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# similar behavior for lists of strings\n",
    "s1[[\"a\", \"b\", \"penguin\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# index has dtype int, so list of strings returns NaN's everywhere\n",
    "s2[[\"a\", \"b\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lists of True/False work the same for any dtype of index\n",
    "bools = [True, False, False, True]\n",
    "s1[bools]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s2[bools]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='boolean'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean selection  \n",
    "\n",
    "We choose observations that satisfy one or more conditions.  Boolean selection consists of two steps that we typically combine in one statement:\n",
    "\n",
    "* Use a comparison to construct a Boolean variable consisting of True and False.  \n",
    "* Compute `df[comparison]`, where `df` is a dataframe and `comparison` is a comparison.  This will select the observations (rows) for which `comparison` is true and throw away the others. \n",
    "\n",
    "We work through this one step at a time:  \n",
    "\n",
    "* Example:  apply the want operator  \n",
    "* Comparisons for dataframes \n",
    "* Boolean selection:  select observations for which the comparison is `True`\n",
    "* The `isin` method\n",
    "\n",
    "This is easier to describe with an example.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:  Apply the want operator to WEO\n",
    "\n",
    "Our **want** here is to take the `weo` dataframe and extract government debt and deficits for a given set of countries.  Putting this to work involves several steps.  \n",
    "\n",
    "Here's the head of the dataframe to remind us what we're dealing with.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weo.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Find variable and country codes.** Which ones do we want?  Let's start by seeing that's available.  Here we create special dataframes that include all the variables and their definitions and all the countries.  \n",
    "\n",
    "Note the use of the `drop_duplicates` method, which does what it sounds like: remove duplicate rows (!)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "variable_list = weo[['Country', 'Subject Descriptor', 'Units']].drop_duplicates()\n",
    "print('Number of variables: ', variable_list.shape[0])\n",
    "variable_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "country_list = weo['Country'].drop_duplicates()\n",
    "print('Number of countries: ', country_list.shape[0])\n",
    "country_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** \n",
    "\n",
    "* Construct a list of countries with `countries = weo['Country']`; that is, without applying the `drop_duplicates` method.  How large is it?  How many duplicates have we dropped?  \n",
    "\n",
    "<!-- cn = sorted(list(set(weo.index))) -->\n",
    "\n",
    "\n",
    "<!--\n",
    "* What are the country codes (`ISO`) for Argentina and the United States?  \n",
    "* What are the variable codes (`WEO Subject Code`) for government debt (gross debt, percent of GDP) and net lending/borrowing (also percent of GDP)?  \n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment.** Now that we have the country and variable codes, we can be more explicit about what we want.  We want observations with those country and variable codes.  \n",
    "\n",
    "We work up to the solution one step at a time.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparisons for series \n",
    "\n",
    "We can construct comparisons for series (dataframe columns) much as we did with simple variables.  The difference is that we get a complete column of True/False responses, not just one.  \n",
    "\n",
    "Mutiple comparisons have a different syntax than we saw earlier: `and` is replaced by `&`, and `or` is replaced by `|`.  And when we have more than one comparison, we need to enclose them in parentheses.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examples.**  Consider the comparisons:  \n",
    "\n",
    "* `small['Units'] == 'National currency'`\n",
    "* `small['2011'] >= 100`\n",
    "* `(small['Units'] == 'National currency') & (small['2011'] >= 100)`\n",
    "* `(small['Units'] == 'National currency') | (small['2011'] >= 100)`\n",
    "\n",
    "Remind yourself what the `&` and `|` do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small['Units'] == 'National currency'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small['2011'] >= 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(small['Units'] == 'National currency') & (small['2011'] >= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(small['Units'] == 'National currency') | (small['2011'] >= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean selection\n",
    "\n",
    "Boolean selection simply chooses those observations for which a condition is `True`.  Some people refer to this as filtering.  The syntax is \n",
    "\n",
    "```python\n",
    "df[comparison]\n",
    "```\n",
    "\n",
    "The result is a new dataframe of observations in which `comparison` is true.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example.**  We choose obervations for which the units are `'National currency'`.  We do this first in two steps, then in one.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remind ourslves what we're starting with \n",
    "small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# two steps:  comparison, then selection \n",
    "ncunits = small['Units'] == 'National currency'   # comparison\n",
    "print(ncunits)\n",
    "small[ncunits]                                    # selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# put the steps together in one line \n",
    "small[small['Units'] == 'National currency']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Construct dataframes for which \n",
    "\n",
    "* `small['Units']` does **not** equal `'National currency'`.\n",
    "* `small['Units']` equals `'National currency'` and `small['2011']` is greater than 100.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='isin'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `isin` method\n",
    "\n",
    "Pay attention now, this is really useful.  Suppose we want to extract the data for which `weo['Country'] == 'Argentina'` or `weo['Country'] == 'Greece'` (Greece).  We could do that by combining the comparisons:  \n",
    "\n",
    "```python\n",
    "(weo['Country'] == 'Aregentina') | (weo['Country'] == 'Greece')\n",
    "```\n",
    "\n",
    "Remind youself that `|` stands for \"or.\"  (What do we use for \"and\"?) \n",
    "\n",
    "A simpler approach is to apply the `isin` method to a variable.  This sets the comparison equal to `True` if the value of the observation is of `weo['Country']` equals any element in a list.  We could do the same thing using mulitple comparisons, but this is a lot easier.  \n",
    "\n",
    "Let's see how this works.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example.**  Let's apply the same logic to variable codes.  If we want to extract the observations with codes \n",
    "```\n",
    "vlist = ['GGXWDG_NGDP', 'GGXCNL_NGDP']\n",
    "```\n",
    "\n",
    "we would use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'WEO Subject Code'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/Users/Tim/anaconda/lib/python3.6/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2133\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2134\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2135\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4433)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4279)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13742)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13696)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'WEO Subject Code'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-96d64cfa2d8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'GGXWDG_NGDP'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'GGXCNL_NGDP'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mweo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'WEO Subject Code'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Tim/anaconda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2057\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Tim/anaconda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2064\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2066\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Tim/anaconda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1384\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1386\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1387\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Tim/anaconda/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3542\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3543\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3544\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3545\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Tim/anaconda/lib/python3.6/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2134\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2136\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4433)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4279)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13742)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13696)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'WEO Subject Code'"
     ]
    }
   ],
   "source": [
    "vlist = ['GGXWDG_NGDP', 'GGXCNL_NGDP']\n",
    "weo['WEO Subject Code'].isin(vlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment.** We're choosing 2 variables from 45, so there are lots of Falses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weo.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this time let's use the result of isin for selection \n",
    "vlist = ['GGXWDG_NGDP', 'GGXCNL_NGDP']\n",
    "weo[weo['WEO Subject Code'].isin(vlist)].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we've combined several things in one line\n",
    "comparison = weo['WEO Subject Code'].isin(vlist) \n",
    "selection  = weo[comparison]\n",
    "selection.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment.** We can do the same thing with countries.  If we want to choose two variables **and** three countries, the code looks like:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variables = ['GGXWDG_NGDP', 'GGXCNL_NGDP']\n",
    "countries = ['Argentina', 'Greece']\n",
    "weo_sub = weo[weo['WEO Subject Code'].isin(variables) & weo['Country'].isin(countries)]\n",
    "weo_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments.**\n",
    "\n",
    "* We've now done what we described when we applied the want operator. \n",
    "* This is a go-to method.  Circle it for later reference.  \n",
    "* **This is a go-to method.  Circle it for later reference.**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Use the `isin` method to extract *Gross domestic product in US dollars* for China, India, and the United States.  Assign the result to the dataframe `gdp`.  *Hint:*  You can adapt the code we just ran. The variable code is NGDPD.  The country codes are CHN, IND, and USA.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "countries = ['China', 'India', 'United States']\n",
    "\n",
    "gdp = weo[(weo['WEO Subject Code']=='NGDPD') & weo['Country'].isin(countries)]\n",
    "gdp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise (challenging).** Plot the variable `gdp['2015']` as a bar chart.  What would you say it needs?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gdp['2015'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='contains'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `contains` method\n",
    "\n",
    "Another useful one.  The `contains` **string method** for series identifies observations that contain a specific string.  If yes, the observation is labelled True, if no, False.  A little trick converts the True/False outcomes to ones and zeros.  \n",
    "\n",
    "We apply it to the `Topics` variable of the Entry Poll dataframe `entry_poll`.  You may recall that this variable could have more than one response.  We tease them apart with the `contains` method.  Our want is to have a yes/no variable for each response.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# recall\n",
    "entry_poll['Topics'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the contains method\n",
    "entry_poll['Topics'].str.contains('Machine Learning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment.** That's pretty good, we now know which students mentioned Machine Learning and which did not.  It's more useful, though, to convert this to zeros (False) and ones (True), which we do with this trick:  we multiply by 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entry_poll['Topics'].str.contains('Machine Learning').head(10)*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment.** Now let's do the same for some of the other entries and save them in new variables.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics = ['Web scraping', 'Machine Learning', 'regression'] \n",
    "old_ep = entry_poll.copy()\n",
    "\n",
    "vnames = []\n",
    "for x in topics:\n",
    "    newname = 'Topics' + '_' + x \n",
    "    vnames.append(newname)\n",
    "    entry_poll[newname] = entry_poll['Topics'].str.contains(x)*1\n",
    "    \n",
    "vnames    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment.** You might want to think about this a minute.  Or two.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create new df of just these variables \n",
    "student_topics = entry_poll[vnames]\n",
    "student_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# count them with the sum method \n",
    "topics_counts = student_topics.sum()\n",
    "topics_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment.** Just for fun, here's a bar graph of the result.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics_counts.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and a pie chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics_counts.plot(kind='pie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Review\n",
    "\n",
    "Let's remind ourselves what we've learned.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** We explore the Census's [Business Dynamics Statistics](http://www.census.gov/ces/dataproducts/bds/), a huge collection of data about firms. We've extracted a small piece of one of their databases that includes these variables for 2013:\n",
    "\n",
    "* Size: size category of firms based on number of employees\n",
    "* Firms: number of firms in each size category\n",
    "* Emp: number of employees in each size category\n",
    "\n",
    "Run the code cell below to load the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = {'Size': ['a) 1 to 4', 'b) 5 to 9', 'c) 10 to 19', 'd) 20 to 49', 'e) 50 to 99',\n",
    "                 'f) 100 to 249', 'g) 250 to 499', 'h) 500 to 999', 'i) 1000 to 2499',\n",
    "                 'j) 2500 to 4999', 'k) 5000 to 9999', 'l) 10000+'], \n",
    "        'Firms': [2846416, 1020772, 598153, 373345, 115544, 63845,\n",
    "                  19389, 9588, 6088, 2287, 1250, 1357], \n",
    "        'Emp': [5998912, 6714924, 8151891, 11425545, 8055535, 9788341, \n",
    "                6611734, 6340775, 8321486, 6738218, 6559020, 32556671]}\n",
    "bds = pd.DataFrame(data) \n",
    "bds .head(3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Use the dataframe `bds` to:  \n",
    "\n",
    "* Compute the mean number of firms with `nbar = bds['Firms'].mean()`. \n",
    "* Generate the new variable `bds['AboveMean']` that is `True` if the value of `bds['Firms']` is above the mean, `False` otherwise. \n",
    "* What dtype is this new variable?  \n",
    "* Select the observations for which the number of firms is above the mean.  \n",
    "* *Challenging.*  Fix the size categories.  Specifically, use a string method to eliminate the prefixes `a)`, `b)`, etc.  That is, change `a) 1 to 4` to `1 to 4`, `b) 5 to 9` to `5 to 9`, and so on.  *Hint:* Use the `split` method.  "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
